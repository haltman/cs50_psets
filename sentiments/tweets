#!/usr/bin/env python3

import os
import sys
import helpers
import nltk

from analyzer import Analyzer
from termcolor import colored

def main():

    # ensure proper usage
    if len(sys.argv) != 2:
        sys.exit("Usage: ./tweets @screen_name")
    else:
        screen_name = sys.argv[1]

    i = 0

    # obtain 50 most recent tweets from screen name entered by user
    tweets = helpers.get_user_timeline(screen_name, 50)
    if tweets == None:
        sys.exit(1)
    else:
        # instantiate tokenizer
        tokenizer = nltk.tokenize.TweetTokenizer()

        # absolute paths to lists
        positives = os.path.join(sys.path[0], "positive-words.txt")
        negatives = os.path.join(sys.path[0], "negative-words.txt")

        # instantiate analyzer
        analyzer = Analyzer(positives, negatives)

        for tweet in tweets:
            # instantiate tokenizer cont'd
            tokens = tokenizer.tokenize(tweets[i])

            # analyze tweets
            score = analyzer.analyze(str(tokens))
            if score > 0.0:
                print(colored("{} {}".format(score, tweets[i]), "green"))
            elif score < 0.0:
                print(colored("{} {}".format(score, tweets[i]), "red"))
            else:
                print(colored("{} {}".format(score, tweets[i]), "yellow"))

            i += 1

if __name__ == "__main__":
    main()


